{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_final_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aminfadaei116/Deep-Learning-Course/blob/master/Final%20Project/DL_final_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBysmYz9_OCX",
        "colab_type": "text"
      },
      "source": [
        "# Installing the Required Pakages and Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v81NEhJ1YxMU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BuJmaxlaGCn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c6e96ced-ac80-4c05-ebe8-b448a8df8cbe"
      },
      "source": [
        "!git clone https://github.com/mcordts/cityscapesScripts.git\n",
        "!pip install GPUtil\n",
        "!pip install -q tf-nightly-2.0-preview\n",
        "\n",
        "import pickle\n",
        "import time\n",
        "from cityscapesScripts.cityscapesscripts.helpers.labels import labels, name2label, id2label, trainId2label, category2labels\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchvision import transforms, datasets, models\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "from imgaug.augmentables import Keypoint, KeypointsOnImage\n",
        "import csv\n",
        "from torchvision.models.utils import load_state_dict_from_url\n",
        "from collections import OrderedDict\n",
        "import GPUtil as GPU\n",
        "from collections import namedtuple\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'cityscapesScripts' already exists and is not an empty directory.\n",
            "Requirement already satisfied: GPUtil in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tf-nightly-2.0-preview (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for tf-nightly-2.0-preview\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYJBeNADIFn1",
        "colab_type": "text"
      },
      "source": [
        "# Start Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hu4OgtUdIIvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "\n",
        "logs_base_dir = \"runs\"\n",
        "os.makedirs(logs_base_dir, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1l87aac_Yy1",
        "colab_type": "text"
      },
      "source": [
        "# Downloading the Cityscape Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctukuQVYZSeR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "\n",
        "PACKAGE_IDS=(1, 3)\n",
        "\n",
        "mkdir dataset\n",
        "\n",
        "wget --keep-session-cookies --save-cookies=cookies.txt --post-data \"username=arashito&password=arashito&submit=Login\" https://www.cityscapes-dataset.com/login/\n",
        "\n",
        "for ID in ${PACKAGE_IDS[@]}; do\n",
        "  wget -O temp.zip --load-cookies cookies.txt --content-disposition \"https://www.cityscapes-dataset.com/file-handling/?packageID=$ID\"\n",
        "  unzip temp.zip -d dataset\n",
        "  rm temp.zip\n",
        "done\n",
        "\n",
        "rm index.html\n",
        "rm cookies.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgfHkc-o0trD",
        "colab_type": "text"
      },
      "source": [
        "# Label Info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIFGk5BBduVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "desired_labels = ['road',\n",
        "                  'sidewalk',\n",
        "                  'parking',\n",
        "                  'building',\n",
        "                  'fence',\n",
        "                  'wall',\n",
        "                  'vegetation',\n",
        "                  'terrain',\n",
        "                  'car',\n",
        "                  'bicycle',\n",
        "                  'bus',\n",
        "                  'truck',\n",
        "                  'sky',\n",
        "                  'person',\n",
        "                  'pole',\n",
        "                  'traffic sign',\n",
        "                  'static',\n",
        "                  'ground',\n",
        "                  'dynamic']\n",
        "\n",
        "\n",
        "Label = namedtuple('Label_info', ['name', 'original_id', 'id', 'color'])\n",
        "\n",
        "label2info = {}\n",
        "\n",
        "for id, label in enumerate(desired_labels):\n",
        "    label2info[label] = Label(name=name2label[label].name, original_id=name2label[label].id, id=id+1, color=name2label[label].color)\n",
        "label2info[None] = Label(name=name2label['unlabeled'].name, original_id=name2label['unlabeled'].id, id=0, color=name2label['unlabeled'].color)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btbdheihpNaj",
        "colab_type": "text"
      },
      "source": [
        "# Processing Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHbAp4b99w0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "\n",
        "cd /content/dataset\n",
        "find . -name '*.json' -type f -delete\n",
        "find . -name '*_color.png' -type f -delete\n",
        "find . -name '*_instanceIds.png' -type f -delete"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohWCBlCWqeYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ORIGINAL_LABELS = range(36)\n",
        "\n",
        "label_map_dict = {label_info.original_id:label_info.id for label_info in label2info.values()}\n",
        "unknown_label = label2info[None].id\n",
        "\n",
        "for original_label in ORIGINAL_LABELS:\n",
        "    if original_label not in label_map_dict:\n",
        "        label_map_dict[original_label]=unknown_label\n",
        "\n",
        "\n",
        "gt_path = '/content/dataset/gtFine'\n",
        "\n",
        "counter=1\n",
        "for root, dirs, files in os.walk(gt_path):\n",
        "  for file in files:\n",
        "      if file.endswith('labelIds.png'):\n",
        "          print('\\r', counter, end='')\n",
        "          image_arr = np.array(Image.open(root+'/'+file))\n",
        "          modified_img = np.vectorize(label_map_dict.get)(image_arr).astype(np.uint8)\n",
        "          glob = modified_img.copy()\n",
        "          modified_img = Image.fromarray(modified_img)\n",
        "          modified_img.save(root+'/'+file[:-4]+'_modified.png')\n",
        "          counter+=1\n",
        "print('\\rfinish!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR0ZKHpi_g4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "\n",
        "cd /content/dataset\n",
        "find . -name '*labelIds.png' -type f -delete"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okbMQxA7rITS",
        "colab_type": "text"
      },
      "source": [
        "# Reading the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa7q9goqF2X_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_files(img_dir, gt_dir, output_name):\n",
        "    \n",
        "    img_paths=[]\n",
        "    gt_paths=[]\n",
        "\n",
        "    for subdir in os.listdir(img_dir):\n",
        "        \n",
        "        imgs=[]\n",
        "        gts=[]\n",
        "        \n",
        "        for file in os.listdir(img_dir+'/'+subdir):\n",
        "            imgs.append(img_dir+'/'+subdir+'/'+file)\n",
        "        \n",
        "        for file in os.listdir(gt_dir+'/'+subdir):\n",
        "                gts.append(gt_dir+'/'+subdir+'/'+file)\n",
        "\n",
        "        assert len(imgs)==len(gts)\n",
        "\n",
        "        imgs.sort()\n",
        "        gts.sort()\n",
        "\n",
        "        img_paths.extend(imgs)\n",
        "        gt_paths.extend(gts)\n",
        "\n",
        "    paths = (img_paths, gt_paths)\n",
        "\n",
        "    return paths"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRMJJut7rO5C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_files = read_files(img_dir='/content/dataset/leftImg8bit/train', gt_dir='/content/dataset/gtFine/train', output_name='train')\n",
        "test_files = read_files(img_dir='/content/dataset/leftImg8bit/test', gt_dir='/content/dataset/gtFine/test', output_name='test')\n",
        "val_files = read_files(img_dir='/content/dataset/leftImg8bit/val', gt_dir='/content/dataset/gtFine/val', output_name='val')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3L7QiP5P44st",
        "colab_type": "text"
      },
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfUFpleC5FPD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def augment_data(aug, files, n_augmentation, augmented_img_path, augmented_gt_path):\n",
        "    \n",
        "    try:\n",
        "        os.makedirs(augmented_img_path)\n",
        "    except FileExistsError:\n",
        "        pass\n",
        "\n",
        "    try:\n",
        "        os.makedirs(augmented_gt_path)\n",
        "    except FileExistsError:\n",
        "        pass\n",
        "\n",
        "    \n",
        "    if augmented_img_path[-1]!='/': augmented_img_path = augmented_img_path + '/'\n",
        "    if augmented_gt_path[-1]!='/': augmented_gt_path = augmented_gt_path + '/'\n",
        "    \n",
        "    img_paths, gt_paths = files\n",
        "    indices = np.random.randint(0,len(img_paths)-1, n_augmentation)\n",
        "\n",
        "\n",
        "    for count, idx in enumerate(indices):\n",
        "\n",
        "        img_path = img_paths[idx]\n",
        "        gt_path = gt_paths[idx]\n",
        "\n",
        "        img = np.array(Image.open(img_path))\n",
        "        gt = np.expand_dims(np.array(Image.open(gt_path)), axis=0)\n",
        "\n",
        "        imag_aug, gt_aug = aug(image=img, segmentation_maps=gt)\n",
        "\n",
        "        imag_aug = Image.fromarray(imag_aug)\n",
        "        gt_aug = Image.fromarray(gt_aug[0])\n",
        "\n",
        "        imag_aug.save(augmented_img_path+img_path.split('/')[-1][:-4]+'_augmented{}.png'.format(count+1))\n",
        "        gt_aug.save(augmented_gt_path+gt_path.split('/')[-1][:-4]+'_augmented{}.png'.format(count+1))\n",
        "\n",
        "        print('\\r', count+1, end='')\n",
        "\n",
        "    print('\\rfinish', end='')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT09P2kQ5Kvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aug = iaa.Sequential([iaa.Crop(percent=(0, 0.4)),\n",
        "                      iaa.LinearContrast((0.75, 1.25)),\n",
        "                      iaa.Multiply((0.8, 1.2), per_channel=0.2),\n",
        "                      iaa.AdditivePoissonNoise((10,20))\n",
        "                      ], random_order=True)\n",
        "\n",
        "files = train_files\n",
        "\n",
        "n_augmentation = 1000\n",
        "\n",
        "augmented_img_path = '/content/dataset/leftImg8bit/train/augmented'\n",
        "augmented_gt_path =  '/content/dataset/gtFine/train/augmented'\n",
        "\n",
        "augment_data(aug, files, n_augmentation, augmented_img_path, augmented_gt_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3v_UsIj5OhA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_files = read_files(img_dir='/content/dataset/leftImg8bit/train', gt_dir='/content/dataset/gtFine/train', output_name='train')\n",
        "test_files = read_files(img_dir='/content/dataset/leftImg8bit/test', gt_dir='/content/dataset/gtFine/test', output_name='test')\n",
        "val_files = read_files(img_dir='/content/dataset/leftImg8bit/val', gt_dir='/content/dataset/gtFine/val', output_name='val')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCXZ8lX15CXr",
        "colab_type": "text"
      },
      "source": [
        "#Building the Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wku7je2CrMkY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset:\n",
        "\n",
        "    IMAGE_TRANSFORM = transforms.Compose([transforms.ToTensor()])\n",
        "    LABEL_TRANSFORM = transforms.Compose([transforms.Lambda(lambda PIL_label: torch.IntTensor(np.array(PIL_label)))])\n",
        "\n",
        "    def __init__(self, images, ground_truths):\n",
        "        \n",
        "        assert len(images)==len(ground_truths)\n",
        "\n",
        "        self.images = images\n",
        "        self.ground_truths = ground_truths\n",
        "        self.samples = list(zip(self.images, self.ground_truths))\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "      \n",
        "        return len(self.samples)\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        if isinstance(index, int):\n",
        "            image_path, gt_path = self.samples[index]\n",
        "            image, gt = Image.open(image_path), Image.open(gt_path)\n",
        "            return (self.IMAGE_TRANSFORM(image), self.LABEL_TRANSFORM(gt))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTdf2T6KrbLS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_set = Dataset(*train_files)\n",
        "test_set = Dataset(*test_files)\n",
        "val_set = Dataset(*val_files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdxbMblgA5UW",
        "colab_type": "text"
      },
      "source": [
        "# Building the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jRzUKZsnU5x",
        "colab_type": "text"
      },
      "source": [
        "## Segmentation Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ox2JD7gCnZWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ASPPConv(nn.Sequential):\n",
        "    \n",
        "    def __init__(self, in_channels, out_channels, dilation):\n",
        "        \n",
        "        modules = [nn.Conv2d(in_channels, out_channels, 3, padding=dilation, dilation=dilation, bias=False),\n",
        "                   nn.BatchNorm2d(out_channels),\n",
        "                   nn.ReLU(inplace=True)]\n",
        "\n",
        "        super(ASPPConv, self).__init__(*modules)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class ASPPPooling(nn.Sequential):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "\n",
        "        super(ASPPPooling, self).__init__(nn.AdaptiveAvgPool2d(1),\n",
        "                                          nn.Conv2d(in_channels, out_channels, 1, bias=False),\n",
        "                                          nn.BatchNorm2d(out_channels),\n",
        "                                          nn.ReLU(inplace=True))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        size = x.shape[-2:]\n",
        "        x = super(ASPPPooling, self).forward(x)\n",
        "        return F.interpolate(x, size=size, mode='bilinear', align_corners=False)\n",
        "\n",
        "\n",
        "\n",
        "class ASPP(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, atrous_rates):\n",
        "\n",
        "        super(ASPP, self).__init__()\n",
        "\n",
        "        out_channels = 256\n",
        "\n",
        "        modules = []\n",
        "\n",
        "        modules.append(nn.Sequential(nn.Conv2d(in_channels, out_channels, 1, bias=False),\n",
        "                                     nn.BatchNorm2d(out_channels),\n",
        "                                     nn.ReLU(inplace=True)))\n",
        "\n",
        "        rate1, rate2, rate3 = tuple(atrous_rates)\n",
        "\n",
        "        modules.append(ASPPConv(in_channels, out_channels, rate1))\n",
        "        modules.append(ASPPConv(in_channels, out_channels, rate2))\n",
        "        modules.append(ASPPConv(in_channels, out_channels, rate3))\n",
        "        modules.append(ASPPPooling(in_channels, out_channels))\n",
        "\n",
        "        self.convs = nn.ModuleList(modules)\n",
        "\n",
        "        self.project = nn.Sequential(\n",
        "            nn.Conv2d(5 * out_channels, out_channels, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.1),)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        res = []\n",
        "        for conv in self.convs:\n",
        "            res.append(conv(x))\n",
        "        res = torch.cat(res, dim=1)\n",
        "        return self.project(res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIhhLPUtnsFd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DeepLabHeadV3Plus(nn.Module):\n",
        "\n",
        "\n",
        "    def __init__(self, in_channels, low_level_channels, num_classes, aspp_dilate=[12, 24, 36]):\n",
        "\n",
        "        super(DeepLabHeadV3Plus, self).__init__()\n",
        "\n",
        "        self.project = nn.Sequential(nn.Conv2d(low_level_channels, 48, 1, bias=False),\n",
        "                                     nn.BatchNorm2d(48),\n",
        "                                     nn.ReLU(inplace=True))\n",
        "\n",
        "        self.aspp = ASPP(in_channels, aspp_dilate)\n",
        "\n",
        "        self.classifier = nn.Sequential(nn.Conv2d(304, 256, 3, padding=1, bias=False),\n",
        "                                        nn.BatchNorm2d(256),\n",
        "                                        nn.ReLU(inplace=True),\n",
        "                                        nn.Conv2d(256, num_classes, 1))\n",
        "        self._init_weight()\n",
        "\n",
        "\n",
        "    def forward(self, feature):\n",
        "        global aba\n",
        "        aba = feature\n",
        "        low_level_feature = self.project(feature['low_level'])\n",
        "        output_feature = self.aspp(feature['out'])\n",
        "        output_feature = F.interpolate(output_feature, size=low_level_feature.shape[2:], mode='bilinear', align_corners=False)\n",
        "        return self.classifier(torch.cat([low_level_feature, output_feature], dim=1))\n",
        "    \n",
        "\n",
        "    def _init_weight(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class DeepLabHead(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, num_classes, aspp_dilate=[12, 24, 36]):\n",
        "\n",
        "        super(DeepLabHead, self).__init__()\n",
        "\n",
        "        self.classifier = nn.Sequential(ASPP(in_channels, aspp_dilate),\n",
        "                                        nn.Conv2d(256, 256, 3, padding=1, bias=False),\n",
        "                                        nn.BatchNorm2d(256),\n",
        "                                        nn.ReLU(inplace=True),\n",
        "                                        nn.Conv2d(256, num_classes, 1))\n",
        "        \n",
        "        self._init_weight()\n",
        "\n",
        "\n",
        "    def forward(self, feature):\n",
        "        return self.classifier( feature['out'] )\n",
        "\n",
        "\n",
        "    def _init_weight(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LTGP1uLnmSK",
        "colab_type": "text"
      },
      "source": [
        "## trunk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrkrHr1SSbvd",
        "colab_type": "text"
      },
      "source": [
        "## ResNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rP4veemdscWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    \n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "      \n",
        "        super(Bottleneck, self).__init__()\n",
        "\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "\n",
        "        width = int(planes * (base_width / 64.)) * groups\n",
        "\n",
        "        self.conv1 = conv1x1(inplanes, width)\n",
        "        self.bn1 = norm_layer(width)\n",
        "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
        "        self.bn2 = norm_layer(width)\n",
        "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
        "        self.bn3 = norm_layer(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        identity = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmXIK5Wbsdky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n",
        "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
        "                 norm_layer=None):\n",
        "\n",
        "        super(ResNet, self).__init__()\n",
        "\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "\n",
        "        self._norm_layer = norm_layer\n",
        "\n",
        "        self.inplanes = 64\n",
        "\n",
        "        self.dilation = 1\n",
        "\n",
        "        if replace_stride_with_dilation is None:\n",
        "            # each element in the tuple indicates if we should replace\n",
        "            # the 2x2 stride with a dilated convolution instead\n",
        "            replace_stride_with_dilation = [False, False, False]\n",
        "\n",
        "        if len(replace_stride_with_dilation) != 3:\n",
        "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
        "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
        "        self.groups = groups\n",
        "\n",
        "        self.base_width = width_per_group\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "\n",
        "        self.bn1 = norm_layer(self.inplanes)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[0])\n",
        "\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[1])\n",
        "\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[2])\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        previous_dilation = self.dilation\n",
        "        if dilate:\n",
        "            self.dilation *= stride\n",
        "            stride = 1\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                norm_layer(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
        "                            self.base_width, previous_dilation, norm_layer))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
        "                                base_width=self.base_width, dilation=self.dilation,\n",
        "                                norm_layer=norm_layer))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eDdUtBmSIkB",
        "colab_type": "text"
      },
      "source": [
        "## MobileNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hb2Yhn7nHAXr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _make_divisible(v, divisor, min_value=None):\n",
        "\n",
        "    if min_value is None:\n",
        "        min_value = divisor\n",
        "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
        "    \n",
        "    if new_v < 0.9 * v:\n",
        "        new_v += divisor\n",
        "    return new_v\n",
        "\n",
        "\n",
        "def fixed_padding(kernel_size, dilation):\n",
        "  \n",
        "    kernel_size_effective = kernel_size + (kernel_size - 1) * (dilation - 1)\n",
        "    pad_total = kernel_size_effective - 1\n",
        "    pad_beg = pad_total // 2\n",
        "    pad_end = pad_total - pad_beg\n",
        "    return (pad_beg, pad_end, pad_beg, pad_end) \n",
        "\n",
        "\n",
        "\n",
        "class ConvBNReLU(nn.Sequential):\n",
        "\n",
        "    def __init__(self, in_planes, out_planes, kernel_size=3, stride=1, dilation=1, groups=1):\n",
        "        \n",
        "        super(ConvBNReLU, self).__init__(nn.Conv2d(in_planes, out_planes, kernel_size, stride, 0, dilation=dilation, groups=groups, bias=False),\n",
        "                                         nn.BatchNorm2d(out_planes),\n",
        "                                         nn.ReLU6(inplace=True))\n",
        "        \n",
        "\n",
        "\n",
        "class InvertedResidual(nn.Module):\n",
        "  \n",
        "    def __init__(self, inp, oup, stride, dilation, expand_ratio):\n",
        "        \n",
        "        super(InvertedResidual, self).__init__()\n",
        "        \n",
        "        self.stride = stride\n",
        "        assert stride in [1, 2]\n",
        "\n",
        "        hidden_dim = int(round(inp * expand_ratio))\n",
        "        self.use_res_connect = self.stride == 1 and inp == oup\n",
        "\n",
        "        layers = []\n",
        "        if expand_ratio != 1:\n",
        "            layers.append(ConvBNReLU(inp, hidden_dim, kernel_size=1))\n",
        "\n",
        "        layers.extend([ConvBNReLU(hidden_dim, hidden_dim, stride=stride, dilation=dilation, groups=hidden_dim),\n",
        "                       nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
        "                       nn.BatchNorm2d(oup),])\n",
        "        \n",
        "        self.conv = nn.Sequential(*layers)\n",
        "\n",
        "        self.input_padding = fixed_padding( 3, dilation )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x_pad = F.pad(x, self.input_padding)\n",
        "        if self.use_res_connect:\n",
        "            return x + self.conv(x_pad)\n",
        "        else:\n",
        "            return self.conv(x_pad)\n",
        "\n",
        "\n",
        "\n",
        "class MobileNetV2(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=1000, output_stride=8, width_mult=1.0, inverted_residual_setting=None, round_nearest=8):\n",
        "\n",
        "        super(MobileNetV2, self).__init__()\n",
        "        block = InvertedResidual\n",
        "        input_channel = 32\n",
        "        last_channel = 1280\n",
        "        self.output_stride = output_stride\n",
        "        current_stride = 1\n",
        "        if inverted_residual_setting is None:\n",
        "            inverted_residual_setting = [[1, 16, 1, 1],\n",
        "                                         [6, 24, 2, 2],\n",
        "                                         [6, 32, 3, 2],\n",
        "                                         [6, 64, 4, 2],\n",
        "                                         [6, 96, 3, 1],\n",
        "                                         [6, 160, 3, 2],\n",
        "                                         [6, 320, 1, 1],]\n",
        "\n",
        "        if len(inverted_residual_setting) == 0 or len(inverted_residual_setting[0]) != 4:\n",
        "            raise ValueError(\"inverted_residual_setting should be non-empty \"\n",
        "                             \"or a 4-element list, got {}\".format(inverted_residual_setting))\n",
        "\n",
        "        input_channel = _make_divisible(input_channel * width_mult, round_nearest)\n",
        "        self.last_channel = _make_divisible(last_channel * max(1.0, width_mult), round_nearest)\n",
        "        features = [ConvBNReLU(3, input_channel, stride=2)]\n",
        "        current_stride *= 2\n",
        "        dilation=1\n",
        "        previous_dilation = 1\n",
        "\n",
        "        for t, c, n, s in inverted_residual_setting:\n",
        "            output_channel = _make_divisible(c * width_mult, round_nearest)\n",
        "            previous_dilation = dilation\n",
        "            if current_stride == output_stride:\n",
        "                stride = 1\n",
        "                dilation *= s\n",
        "            else:\n",
        "                stride = s\n",
        "                current_stride *= s\n",
        "            output_channel = int(c * width_mult)\n",
        "\n",
        "            for i in range(n):\n",
        "                if i==0:\n",
        "                    features.append(block(input_channel, output_channel, stride, previous_dilation, expand_ratio=t))\n",
        "                else:\n",
        "                    features.append(block(input_channel, output_channel, 1, dilation, expand_ratio=t))\n",
        "                input_channel = output_channel\n",
        "\n",
        "        features.append(ConvBNReLU(input_channel, self.last_channel, kernel_size=1))\n",
        "\n",
        "        self.features = nn.Sequential(*features)\n",
        "\n",
        "        self.classifier = nn.Sequential(nn.Dropout(0.2),\n",
        "                                        nn.Linear(self.last_channel, num_classes),)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.ones_(m.weight)\n",
        "                nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.mean([2, 3])\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def mobilenet_v2(pretrained=False, progress=True, **kwargs):\n",
        "  \n",
        "    model = MobileNetV2(**kwargs)\n",
        "    if pretrained:\n",
        "        state_dict = load_state_dict_from_url(model_urls['mobilenet_v2'],\n",
        "                                              progress=progress)\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpYGNCm00oiW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IntermediateLayerGetter(nn.ModuleDict):\n",
        "\n",
        "    def __init__(self, model, return_layers):\n",
        "        if not set(return_layers).issubset([name for name, _ in model.named_children()]):\n",
        "            raise ValueError(\"return_layers are not present in model\")\n",
        "\n",
        "        orig_return_layers = return_layers\n",
        "        return_layers = {k: v for k, v in return_layers.items()}\n",
        "        layers = OrderedDict()\n",
        "        for name, module in model.named_children():\n",
        "            layers[name] = module\n",
        "            if name in return_layers:\n",
        "                del return_layers[name]\n",
        "            if not return_layers:\n",
        "                break\n",
        "\n",
        "        super(IntermediateLayerGetter, self).__init__(layers)\n",
        "        self.return_layers = orig_return_layers\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = OrderedDict()\n",
        "        for name, module in self.named_children():\n",
        "            x = module(x)\n",
        "            if name in self.return_layers:\n",
        "                out_name = self.return_layers[name]\n",
        "                out[out_name] = x\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHjN3z4MshEr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _resnet(arch, block, layers, pretrained, progress, **kwargs):\n",
        "\n",
        "    model = ResNet(block, layers, **kwargs)\n",
        "\n",
        "    if pretrained:\n",
        "        state_dict = load_state_dict_from_url(model_urls[arch],\n",
        "                                              progress=progress)\n",
        "        model.load_state_dict(state_dict)\n",
        "        \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1r5po7_soj7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet50(pretrained=False, progress=True, **kwargs):\n",
        "    \n",
        "    return _resnet('resnet50', Bottleneck, [3, 4, 6, 3], pretrained, progress, **kwargs)\n",
        "\n",
        "\n",
        "def resnet101(pretrained=False, progress=True, **kwargs):\n",
        "\n",
        "    return _resnet('resnet101', Bottleneck, [3, 4, 23, 3], pretrained, progress, **kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeYAEp58gKOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet_dict = {\n",
        "               'resnet101':resnet101,\n",
        "               'resnet50':resnet50,}\n",
        "\n",
        "model_urls = {'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "              'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth'}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgwmW5WxvxMP",
        "colab_type": "text"
      },
      "source": [
        "## Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K81LDlivzrN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Attention(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels):\n",
        "\n",
        "        super(Attention, self).__init__()\n",
        "\n",
        "        self.attention_mask = nn.Sequential(nn.ConvTranspose2d(in_channels=in_channels, out_channels=512, kernel_size=(6,6), stride=2, padding=2),\n",
        "                                            nn.BatchNorm2d(num_features=512),\n",
        "                                            nn.LeakyReLU(negative_slope=0.01),\n",
        "                                            nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=(6,6), stride=2, padding=2),\n",
        "                                            nn.BatchNorm2d(num_features=256),\n",
        "                                            nn.LeakyReLU(negative_slope=0.01),\n",
        "                                            nn.ConvTranspose2d(in_channels=256, out_channels=64, kernel_size=(6,6), stride=2, padding=2),\n",
        "                                            nn.BatchNorm2d(num_features=64),\n",
        "                                            nn.LeakyReLU(negative_slope=0.01),\n",
        "                                            nn.ConvTranspose2d(in_channels=64, out_channels=1, kernel_size=(5,5), stride=1, padding=2),\n",
        "                                            nn.Sigmoid()\n",
        "                                            )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "      \n",
        "      return self.attention_mask(x) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSVwDp9trmi9",
        "colab_type": "text"
      },
      "source": [
        "## Network Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTJQKqu4kR7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _segm_resnet(segmentation_name, backbone_name, num_classes, output_stride, pretrained_backbone):\n",
        "\n",
        "    if output_stride==8:\n",
        "        replace_stride_with_dilation=[False, True, True]\n",
        "        aspp_dilate = [12, 24, 36]\n",
        "    else:\n",
        "        replace_stride_with_dilation=[False, False, True]\n",
        "        aspp_dilate = [6, 12, 18]\n",
        "\n",
        "    backbone = resnet_dict[backbone_name](\n",
        "        pretrained=pretrained_backbone,\n",
        "        replace_stride_with_dilation=replace_stride_with_dilation)\n",
        "    \n",
        "    inplanes = 2048\n",
        "    low_level_planes = 256\n",
        "\n",
        "    return_layers = None\n",
        "    classifier = None\n",
        "\n",
        "    if segmentation_name=='deeplabv3+':\n",
        "        return_layers = {'layer4': 'out', 'layer1': 'low_level'}\n",
        "        classifier = DeepLabHeadV3Plus(inplanes, low_level_planes, num_classes, aspp_dilate)\n",
        "\n",
        "    elif segmentation_name=='deeplabv3':\n",
        "        return_layers = {'layer4': 'out'}\n",
        "        classifier = DeepLabHead(inplanes , num_classes, aspp_dilate)\n",
        "\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    backbone = IntermediateLayerGetter(backbone, return_layers=return_layers)\n",
        "\n",
        "    return backbone, classifier\n",
        "\n",
        "\n",
        "\n",
        "def _segm_mobilenet(name, backbone_name, num_classes, output_stride, pretrained_backbone):\n",
        "    \n",
        "    if output_stride==8:\n",
        "        aspp_dilate = [12, 24, 36]\n",
        "    else:\n",
        "        aspp_dilate = [6, 12, 18]\n",
        "\n",
        "    backbone = mobilenet_v2(pretrained=pretrained_backbone, output_stride=output_stride)\n",
        "    \n",
        "    backbone.low_level_features = backbone.features[0:4]\n",
        "    backbone.high_level_features = backbone.features[4:-1]\n",
        "    backbone.features = None\n",
        "    backbone.classifier = None\n",
        "\n",
        "    inplanes = 320\n",
        "    low_level_planes = 24\n",
        "    \n",
        "    return_layers = None\n",
        "    classifier = None\n",
        "    if name=='deeplabv3+':\n",
        "        return_layers = {'high_level_features': 'out', 'low_level_features': 'low_level'}\n",
        "        classifier = DeepLabHeadV3Plus(inplanes, low_level_planes, num_classes, aspp_dilate)\n",
        "    elif name=='deeplabv3':\n",
        "        return_layers = {'high_level_features': 'out'}\n",
        "        classifier = DeepLabHead(inplanes , num_classes, aspp_dilate)\n",
        "    backbone = IntermediateLayerGetter(backbone, return_layers=return_layers)\n",
        "\n",
        "    return (backbone, classifier)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6P5sTkH1xxe7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InitStage(nn.Module):\n",
        "\n",
        "    def __init__(self, scale, segmentation_name, backbone_name, num_classes, pretrained_backbone=True, freeze_trunk=False, freeze_seg=False):\n",
        "\n",
        "        assert scale>0\n",
        "\n",
        "        super(InitStage, self).__init__()\n",
        "\n",
        "        trunk_loader = None\n",
        "        if backbone_name=='mobilenetv2':\n",
        "            trunk_loader = _segm_mobilenet\n",
        "        elif backbone_name.startswith('resnet'):\n",
        "            trunk_loader = _segm_resnet\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "        \n",
        "        self.trunk, self.segmentation = trunk_loader(segmentation_name, backbone_name, num_classes, output_stride=8, pretrained_backbone=True)\n",
        "        \n",
        "        if freeze_trunk:\n",
        "            self.freeze_trunk()\n",
        "\n",
        "        if freeze_seg:\n",
        "            self.freeze_seg()\n",
        "        \n",
        "        self.scale = scale\n",
        "\n",
        "\n",
        "    \n",
        "    def forward(self, x):\n",
        "\n",
        "        input_shape = x.shape[-2:]\n",
        "        x = F.interpolate(input=x, scale_factor=self.scale, mode='bilinear')\n",
        "        x = self.trunk(x)\n",
        "        x = self.segmentation(x)\n",
        "        x = F.interpolate(x, size=input_shape, mode='bilinear', align_corners=False)\n",
        "        x = F.sigmoid(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "    def freeze_trunk(self):\n",
        "        for p in self.trunk.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "\n",
        "    def freeze_seg(self):\n",
        "        for p in self.segmentation.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "\n",
        "    def unfreeze_trunk(self):\n",
        "        for p in self.trunk.parameters():\n",
        "            p.requires_grad = True\n",
        "\n",
        "\n",
        "    def unfreeze_seg(self):\n",
        "        for p in self.segmentation.parameters():\n",
        "            p.requires_grad = True\n",
        "          \n",
        "\n",
        "    def get_trainable_param(self): \n",
        "        return filter(lambda p: p.requires_grad, self.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmSeAIg6ypfo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Stage(nn.Module):\n",
        "\n",
        "    def __init__(self, scale, segmentation_name, backbone_name, num_classes, freeze_trunk=False, freeze_seg=False):\n",
        "\n",
        "        super(Stage, self).__init__()\n",
        "\n",
        "        trunk_loader = None\n",
        "        trunk_out_channels = None\n",
        "        if backbone_name=='mobilenetv2':\n",
        "            trunk_loader = _segm_mobilenet\n",
        "            trunk_out_channels = 320\n",
        "        elif backbone_name.startswith('resnet'):\n",
        "            trunk_loader = _segm_resnet\n",
        "            trunk_out_channels = 2048\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "        \n",
        "        self.trunk, self.segmentation = trunk_loader(segmentation_name, backbone_name, num_classes, output_stride=8, pretrained_backbone=True)\n",
        "        \n",
        "        if freeze_trunk:\n",
        "            self.freeze_trunk()\n",
        "\n",
        "        if freeze_seg:\n",
        "            self.freeze_seg()\n",
        "\n",
        "        self.attention = Attention(in_channels=trunk_out_channels)\n",
        "\n",
        "        self.scale = scale\n",
        "\n",
        "\n",
        "    def forward(self, x, prev_stage_output):\n",
        "\n",
        "        x = F.interpolate(input=x, scale_factor=self.scale, mode='bilinear')\n",
        "        input_shape = x.shape[2:]\n",
        "\n",
        "        trunk_output = self.trunk(x)\n",
        "\n",
        "        segmentation_output = self.segmentation(trunk_output)\n",
        "        segmentation_output = F.interpolate(segmentation_output, size=input_shape, mode='bilinear', align_corners=False)\n",
        "\n",
        "        attention_output = self.attention(trunk_output['out'])\n",
        "\n",
        "        attention_output = F.interpolate(attention_output, size=input_shape, mode='bilinear', align_corners=False)\n",
        "\n",
        "        new = attention_output * segmentation_output\n",
        "\n",
        "        new = F.interpolate(input=new, scale_factor=1/self.scale, mode='bilinear')\n",
        "\n",
        "        scaled_attention = F.interpolate(input=attention_output, size=prev_stage_output.shape[2:], mode='bilinear')\n",
        "        prev = (1-scaled_attention) * prev_stage_output\n",
        "\n",
        "        output = F.sigmoid(new + prev)\n",
        "\n",
        "        return output\n",
        "\n",
        "    \n",
        "    def freeze_trunk(self):\n",
        "        for p in self.trunk.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "\n",
        "    def freeze_seg(self):\n",
        "        for p in self.segmentation.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "  \n",
        "    def freeze_attention(self):\n",
        "        for p in self.attention.parameters():\n",
        "            p.requires_grad = False\n",
        "      \n",
        "    \n",
        "    def unfreeze_trunk(self):\n",
        "        for p in self.trunk.parameters():\n",
        "            p.requires_grad = True\n",
        "\n",
        "\n",
        "    def unfreeze_seg(self):\n",
        "        for p in self.segmentation.parameters():\n",
        "            p.requires_grad = True\n",
        "\n",
        "\n",
        "    def unfreeze_attention(self):\n",
        "        for p in self.attention.parameters():\n",
        "            p.requires_grad = True\n",
        "\n",
        "\n",
        "    def get_trainable_param(self): \n",
        "\n",
        "        return filter(lambda p: p.requires_grad, self.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPHuAW-4ztsK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HierachicalModel(nn.Module):\n",
        "\n",
        "    def __init__(self, n_stages, scales, segmentation, backbone, n_classes=20):\n",
        "\n",
        "        super(HierachicalModel, self).__init__()\n",
        "\n",
        "        assert type(n_stages)==int and n_stages>0\n",
        "        assert (type(scales)==list or type(scales)==tuple) and len(scales)==n_stages\n",
        "\n",
        "        self.n_classes = n_classes\n",
        "        self.init_stage = InitStage(scale=scales[0], segmentation_name=segmentation, backbone_name=backbone, num_classes=self.n_classes)\n",
        "        self.next_stages = nn.ModuleList([Stage(scale=scale, segmentation_name=segmentation, backbone_name=backbone, num_classes=self.n_classes) for scale in scales[1:]])\n",
        "\n",
        "        # self.sementic_head = nn.Sequential(nn.Conv2d(in_channels=1, out_channels=96, kernel_size=(3,3), stride=4, padding=4),\n",
        "        #                                    nn.BatchNorm2d(100),\n",
        "        #                                    nn.ReLU(),\n",
        "        #                                    nn.Conv2d(in_channels=3, out_channels=96, kernel_size=(3,3), stride=4, padding=4),\n",
        "        #                                    nn.BatchNorm2d(100),\n",
        "        #                                    nn.ReLU(),\n",
        "        #                                    nn.Conv2d(in_channels=3, out_channels=self.N_CLASSES, kernel_size=(1,1), stride=4, padding=4))\n",
        "        \n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        output = self.init_stage(x)\n",
        "\n",
        "        for stage in self.next_stages:\n",
        "            output = stage(x, output)\n",
        "\n",
        "        # output = sementic_head(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "        \n",
        "    def get_trainable_param(self): \n",
        "\n",
        "        return filter(lambda p: p.requires_grad, self.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwuVxYKrnzyg",
        "colab_type": "text"
      },
      "source": [
        "# Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPLbz5p1Pb_d",
        "colab_type": "text"
      },
      "source": [
        "## Implementing the Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiuI8MJCkGsN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RMILoss(nn.Module):\n",
        "\n",
        "    _CLIP_MIN = 1e-6\n",
        "    _CLIP_MAX = 1.0\n",
        "    _POS_ALPHA = 5e-4\n",
        "    _IS_SUM = 1\n",
        "\n",
        "\n",
        "    def __init__(self,\n",
        "                 num_classes=21,\n",
        "                 rmi_radius=3,\n",
        "                 rmi_pool_way=0,\n",
        "                 rmi_pool_size=3,\n",
        "                 rmi_pool_stride=3,\n",
        "                 loss_weight_lambda=0.5,\n",
        "                 lambda_way=1,):\n",
        "   \n",
        "        super(RMILoss, self).__init__()\n",
        "  \n",
        "        assert rmi_radius<=10 and type(rmi_radius)==int\n",
        "        assert rmi_pool_way<=3 and type(rmi_pool_way)==int\n",
        "        assert rmi_pool_size == rmi_pool_stride\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "        self.rmi_radius = rmi_radius\n",
        "        self.rmi_pool_way = rmi_pool_way\n",
        "        self.rmi_pool_size = rmi_pool_size\n",
        "        self.rmi_pool_stride = rmi_pool_stride\n",
        "        self.weight_lambda = loss_weight_lambda\n",
        "        self.lambda_way = lambda_way\n",
        "\n",
        "        self.half_d = self.rmi_radius * self.rmi_radius\n",
        "        self.d = 2 * self.half_d\n",
        "        self.kernel_padding = self.rmi_pool_size//2\n",
        "        self.ignore_index = 255\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, logits_4D, labels_4D):\n",
        "        loss = self.forward_sigmoid(logits_4D, labels_4D)\n",
        "        #loss = self.forward_softmax_sigmoid(logits_4D, labels_4D)\n",
        "        return loss\n",
        "\n",
        "\n",
        "\n",
        "    def forward_softmax_sigmoid(self, logits_4D, labels_4D):\n",
        "\n",
        "        normal_loss = F.cross_entropy(input=logits_4D,\n",
        "                                        target=labels_4D.long(),\n",
        "                                        ignore_index=self.ignore_index,\n",
        "                                        reduction='mean')\n",
        "\n",
        "        label_mask_3D = labels_4D < self.num_classes\n",
        "        valid_onehot_labels_4D = F.one_hot(labels_4D.long() * label_mask_3D.long(), num_classes=self.num_classes).float()\n",
        "        label_mask_3D = label_mask_3D.float()\n",
        "        valid_onehot_labels_4D = valid_onehot_labels_4D * label_mask_3D.unsqueeze(dim=3)\n",
        "        valid_onehot_labels_4D = valid_onehot_labels_4D.permute(0, 3, 1, 2).requires_grad_(False)\n",
        "        probs_4D = F.sigmoid(logits_4D) * label_mask_3D.unsqueeze(dim=1)\n",
        "        probs_4D = probs_4D.clamp(min=self._CLIP_MIN, max=self._CLIP_MAX)\n",
        "        rmi_loss = self.rmi_lower_bound(valid_onehot_labels_4D, probs_4D)\n",
        "\n",
        "        final_loss = (self.weight_lambda * normal_loss + rmi_loss * (1 - self.weight_lambda) if self.lambda_way\n",
        "                        else normal_loss + rmi_loss * self.weight_lambda)\n",
        "\n",
        "        return final_loss\n",
        "\n",
        "\n",
        "    def forward_sigmoid(self, logits_4D, labels_4D):\n",
        "\n",
        "        label_mask_3D = labels_4D < self.num_classes\n",
        "\n",
        "        valid_onehot_labels_4D = F.one_hot(labels_4D.long() * label_mask_3D.long(), num_classes=self.num_classes).float()\n",
        "        label_mask_3D = label_mask_3D.float()\n",
        "        label_mask_flat = label_mask_3D.view([-1, ])\n",
        "        valid_onehot_labels_4D = valid_onehot_labels_4D * label_mask_3D.unsqueeze(dim=3)\n",
        "        valid_onehot_labels_4D.requires_grad_(False)\n",
        "\n",
        "        valid_onehot_label_flat = valid_onehot_labels_4D.view([-1, self.num_classes]).requires_grad_(False)\n",
        "        logits_flat = logits_4D.permute(0, 2, 3, 1).contiguous().view([-1, self.num_classes])\n",
        "\n",
        "        valid_pixels = torch.sum(label_mask_flat)\n",
        "        binary_loss = F.binary_cross_entropy_with_logits(logits_flat,\n",
        "                                                            target=valid_onehot_label_flat,\n",
        "                                                            weight=label_mask_flat.unsqueeze(dim=1),\n",
        "                                                            reduction='sum')\n",
        "        bce_loss = torch.div(binary_loss, valid_pixels + 1.0)\n",
        "\n",
        "        probs_4D = logits_4D.sigmoid() * label_mask_3D.unsqueeze(dim=1) + self._CLIP_MIN\n",
        "        valid_onehot_labels_4D = valid_onehot_labels_4D.permute(0, 3, 1, 2).requires_grad_(False)\n",
        "\n",
        "        rmi_loss = self.rmi_lower_bound(valid_onehot_labels_4D, probs_4D)\n",
        "\n",
        "        final_loss = (self.weight_lambda * bce_loss + rmi_loss * (1 - self.weight_lambda) if self.lambda_way\n",
        "                else bce_loss + rmi_loss * self.weight_lambda)\n",
        "\n",
        "        return final_loss\n",
        "\n",
        "\n",
        "    def rmi_lower_bound(self, labels_4D, probs_4D):\n",
        "\n",
        "        assert labels_4D.size() == probs_4D.size()\n",
        "\n",
        "        p, s = self.rmi_pool_size, self.rmi_pool_stride\n",
        "        if self.rmi_pool_stride > 1:\n",
        "            if self.rmi_pool_way == 0:\n",
        "                labels_4D = F.max_pool2d(labels_4D, kernel_size=p, stride=s, padding=self.kernel_padding)\n",
        "                probs_4D = F.max_pool2d(probs_4D, kernel_size=p, stride=s, padding=self.kernel_padding)\n",
        "            elif self.rmi_pool_way == 1:\n",
        "                labels_4D = F.avg_pool2d(labels_4D, kernel_size=p, stride=s, padding=self.kernel_padding)\n",
        "                probs_4D = F.avg_pool2d(probs_4D, kernel_size=p, stride=s, padding=self.kernel_padding)\n",
        "            elif self.rmi_pool_way == 2:\n",
        "                shape = labels_4D.size()\n",
        "                new_h, new_w = shape[2] // s, shape[3] // s\n",
        "                labels_4D = F.interpolate(labels_4D, size=(new_h, new_w), mode='nearest')\n",
        "                probs_4D = F.interpolate(probs_4D, size=(new_h, new_w), mode='bilinear', align_corners=True)\n",
        "            else:\n",
        "                raise NotImplementedError(\"Pool way of RMI is not defined!\")\n",
        "        label_shape = labels_4D.size()\n",
        "        n, c = label_shape[0], label_shape[1]\n",
        "        la_vectors, pr_vectors = self.map_get_pairs(labels_4D, probs_4D, radius=self.rmi_radius, is_combine=0)\n",
        "        la_vectors = la_vectors.view([n, c, self.half_d, -1]).type(torch.cuda.DoubleTensor).requires_grad_(False)\n",
        "        pr_vectors = pr_vectors.view([n, c, self.half_d, -1]).type(torch.cuda.DoubleTensor)\n",
        "        diag_matrix = torch.eye(self.half_d).unsqueeze(dim=0).unsqueeze(dim=0)\n",
        "        la_vectors = la_vectors - la_vectors.mean(dim=3, keepdim=True)\n",
        "        la_cov = torch.matmul(la_vectors, la_vectors.transpose(2, 3))\n",
        "        pr_vectors = pr_vectors - pr_vectors.mean(dim=3, keepdim=True)\n",
        "        pr_cov = torch.matmul(pr_vectors, pr_vectors.transpose(2, 3))\n",
        "        pr_cov_inv = torch.inverse(pr_cov + diag_matrix.type_as(pr_cov) * self._POS_ALPHA)\n",
        "        la_pr_cov = torch.matmul(la_vectors, pr_vectors.transpose(2, 3))\n",
        "        appro_var = la_cov - torch.matmul(la_pr_cov.matmul(pr_cov_inv), la_pr_cov.transpose(-2, -1))\n",
        "        rmi_now = 0.5 * self.log_det_by_cholesky(appro_var + diag_matrix.type_as(appro_var) * self._POS_ALPHA)\n",
        "        rmi_per_class = rmi_now.view([-1, self.num_classes]).mean(dim=0).float()\n",
        "\n",
        "        rmi_per_class = torch.div(rmi_per_class, float(self.half_d))\n",
        "        rmi_loss = torch.sum(rmi_per_class) if self._IS_SUM else torch.mean(rmi_per_class)\n",
        "\n",
        "        return rmi_loss\n",
        "\n",
        "\n",
        "\n",
        "    def map_get_pairs(aelf, labels_4D, probs_4D, radius=3, is_combine=True):\n",
        "\n",
        "        h, w = labels_4D.size()[2:4]\n",
        "\n",
        "        new_h, new_w = h-(radius-1), w-(radius-1)\n",
        "    \n",
        "        la_ns=[]\n",
        "        pr_ns=[]\n",
        "\n",
        "        for y in range(0, radius):\n",
        "            for x in range(0, radius):\n",
        "                la_now = labels_4D[:, :, y:y+new_h, x:x+new_w]\n",
        "                pr_now = probs_4D[:, :, y:y+new_h, x:x+new_w]\n",
        "                la_ns.append(la_now)\n",
        "                pr_ns.append(pr_now)\n",
        "\n",
        "        if is_combine:\n",
        "            pair_ns = la_ns + pr_ns\n",
        "            p_vectors = torch.stack(pair_ns, dim=2)\n",
        "            return p_vectors\n",
        "        \n",
        "        else:\n",
        "            la_vectors = torch.stack(la_ns, dim=2)\n",
        "            pr_vectors = torch.stack(pr_ns, dim=2)\n",
        "            return la_vectors, pr_vectors\n",
        "\n",
        "\n",
        "    def log_det_by_cholesky(self, matrix):\n",
        "\n",
        "      chol = torch.cholesky(matrix)\n",
        "      return 2.0 * torch.sum(torch.log(torch.diagonal(chol, dim1=-2, dim2=-1) + 1e-8), dim=-1)\n",
        "\n",
        "\n",
        "\n",
        "    def batch_cholesky_inverse(self, matrix):\n",
        "\n",
        "      chol_low = torch.cholesky(matrix, upper=False)\n",
        "      chol_low_inv = self.batch_low_tri_inv(chol_low)\n",
        "      return torch.matmul(chol_low_inv.transpose(-2, -1), chol_low_inv)\n",
        "\n",
        "\n",
        "\n",
        "    def batch_low_tri_inv(self, L):\n",
        "\n",
        "      n = L.shape[-1]\n",
        "      invL = torch.zeros_like(L)\n",
        "      for j in range(0, n):\n",
        "        invL[..., j, j] = 1.0 / L[..., j, j]\n",
        "        for i in range(j + 1, n):\n",
        "          S = 0.0\n",
        "          for k in range(0, i + 1):\n",
        "            S = S - L[..., i, k] * invL[..., k, j].clone()\n",
        "          invL[..., i, j] = S / L[..., i, i]\n",
        "      return invL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tytEKvUQn3Ui",
        "colab_type": "text"
      },
      "source": [
        "## Other Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-cNmt_Tn8Eu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Metrics:\n",
        "\n",
        "    ID2LABEL_NAME = {}\n",
        "    for label, info in label2info.items():\n",
        "        ID2LABEL_NAME[info.id] = label\n",
        "\n",
        "    def mean_pixel_accuracy(pred, gt):\n",
        "\n",
        "        gt = np.array(gt.to('cpu'))\n",
        "        pred = np.array(pred.to('cpu'))\n",
        "\n",
        "        unique, counts = np.unique(gt, return_counts=True)\n",
        "        class_count = dict(zip(unique, counts))\n",
        "\n",
        "        mean_pixel_accuracy = {}\n",
        "        equality = (pred==gt)\n",
        "        values = np.array([pred==id for id in class_count.keys()])\n",
        "        correct_detection = values * equality\n",
        "        for idx, (id, count) in enumerate(class_count.items()):\n",
        "            mean_pixel_accuracy[Metrics.ID2LABEL_NAME[id]] = np.sum(correct_detection[idx])/count\n",
        "        return mean_pixel_accuracy\n",
        "\n",
        "\n",
        "    def IOU_for_classes(pred, gt):\n",
        "\n",
        "        gt = np.array(gt.to('cpu'))\n",
        "        pred = np.array(pred.to('cpu'))\n",
        "\n",
        "        unique, counts = np.unique(gt, return_counts=True)\n",
        "        class_count = dict(zip(unique, counts))\n",
        "\n",
        "        IOU_values = {}\n",
        "\n",
        "        pred_equal_to_id = np.array([pred==id for id in class_count.keys()])\n",
        "        gt_equal_to_id = np.array([gt==id for id in class_count.keys()])\n",
        "\n",
        "        intersection = gt_equal_to_id * pred_equal_to_id\n",
        "        union = gt_equal_to_id + pred_equal_to_id\n",
        "\n",
        "        for idx, (id, count) in enumerate(class_count.items()):\n",
        "            IOU_values[Metrics.ID2LABEL_NAME[id]] = np.sum(intersection[idx])/np.sum(union[idx])\n",
        "        \n",
        "        return IOU_values\n",
        "\n",
        "        \n",
        "    def mean_IOU(pred, gt):\n",
        "\n",
        "        return np.mean(list(Metrics.IOU_for_classes(pred, gt).values()))\n",
        "    \n",
        "\n",
        "    def pixel_accuracy(pred, gt):\n",
        "\n",
        "        assert pred.shape==gt.shape\n",
        "\n",
        "        total_pixels = torch.numel(pred)\n",
        "        correctly_classified_pixels = torch.sum(pred==gt).item()\n",
        "\n",
        "        return correctly_classified_pixels / total_pixels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a555-_Fr24vP",
        "colab_type": "text"
      },
      "source": [
        "# Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYsU9sPs27HJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Trainer():\n",
        "\n",
        "    N_CLASSES = 20\n",
        "    \n",
        "    def __init__(self,\n",
        "                 model,\n",
        "                 optimizer,\n",
        "                 device,\n",
        "                 log_dir=time.strftime(\"/content/runs/RUN-%Y-%m-%d %H:%M:%S\", time.gmtime())):\n",
        "\n",
        "        self.device = device\n",
        "        self.model = model.to(self.device)\n",
        "        self.optimizer = optimizer\n",
        "        self.loss = RMILoss(num_classes=self.N_CLASSES)\n",
        "        self.writer = SummaryWriter(log_dir=log_dir)\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "    def train_model(self, train_loader, epoch_number, print_results=True):\n",
        "        \n",
        "        assert epoch_number > 0 and type(epoch_number)==int\n",
        "\n",
        "        self.model.train()\n",
        "\n",
        "        loss_sum = 0\n",
        "        accuracy_sum = 0\n",
        "        mean_IOU_sum = 0\n",
        "\n",
        "        n_batches = int(len(train_loader.dataset) / train_loader.batch_size)\n",
        "        \n",
        "        for n_batch, (data, target) in enumerate(train_loader):\n",
        "            \n",
        "            if len(data)==1: continue\n",
        "            \n",
        "            if self.device.type=='cuda':\n",
        "                torch.cuda.empty_cache()\n",
        "            \n",
        "            data = data.to(self.device)\n",
        "            target = target.to(self.device).long()\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            output = self.model(data)\n",
        "\n",
        "            loss = self.loss(output, target)\n",
        "            average_batch_loss = loss.item()\n",
        "            loss_sum += average_batch_loss\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            batch_pixel_accuracy = Metrics.pixel_accuracy(self.__get_predicted_labels_from_output(output), target)\n",
        "            accuracy_sum += batch_pixel_accuracy\n",
        "            \n",
        "            batch_mean_IOU = Metrics.mean_IOU(self.__get_predicted_labels_from_output(output), target)\n",
        "            mean_IOU_sum += batch_mean_IOU\n",
        "\n",
        "            if print_results:\n",
        "                print('\\rTraining Batch {}/{}:\\tAverage Loss: {:.3f}\\tPixel Accuracy: {:.3f}\\tMean IOU: {:.3f}\\t\\tAverage IOU: {:.3f}'.format(n_batch+1, \n",
        "                                                                                                                                              n_batches, \n",
        "                                                                                                                                              average_batch_loss, \n",
        "                                                                                                                                              batch_pixel_accuracy, \n",
        "                                                                                                                                              batch_mean_IOU, \n",
        "                                                                                                                                              mean_IOU_sum/(n_batch+1)), end='')\n",
        "                if self.device.type=='cuda':\n",
        "                    print('\\tGPU Usage: {:.1f}%'.format(GPU.getGPUs()[0].memoryUtil*100), end='')\n",
        "                    \n",
        "        \n",
        "        average_loss = loss_sum / n_batches\n",
        "        average_accuracy = accuracy_sum / n_batches\n",
        "        average_mean_IOU = mean_IOU_sum / n_batches\n",
        "\n",
        "        self.writer.add_scalar('Loss/train', average_loss, epoch_number)\n",
        "        self.writer.add_scalar('pixel_accuracy/train', average_accuracy, epoch_number)\n",
        "        self.writer.add_scalar('mean_IOU/train', average_mean_IOU, epoch_number)\n",
        "\n",
        "        if print_results:\n",
        "            print('\\r',end='')\n",
        "\n",
        "        return (average_loss, average_accuracy, average_mean_IOU)\n",
        "\n",
        "\n",
        "         \n",
        "    def test_model(self, test_loader, epoch_number, print_results=True):\n",
        "\n",
        "        assert epoch_number > 0 and type(epoch_number)==int\n",
        "        \n",
        "        self.model.eval()\n",
        "\n",
        "        loss_sum = 0\n",
        "        accuracy_sum = 0\n",
        "        mean_IOU_sum = 0\n",
        "\n",
        "        n_batches = int(len(test_loader.dataset) / test_loader.batch_size)\n",
        "\n",
        "        with torch.no_grad():\n",
        "          for n_batch, (data, target) in enumerate(test_loader):\n",
        "              \n",
        "              if len(data)==1: continue\n",
        "\n",
        "              if self.device.type=='cuda':\n",
        "                  torch.cuda.empty_cache()\n",
        "              \n",
        "              data = data.to(self.device)\n",
        "              target = target.to(self.device).long()\n",
        "              output = self.model(data)\n",
        "              loss = self.loss(output, target)\n",
        "\n",
        "              average_batch_loss = loss.item()\n",
        "              loss_sum += average_batch_loss\n",
        "\n",
        "              batch_pixel_accuracy = Metrics.pixel_accuracy(self.__get_predicted_labels_from_output(output), target)\n",
        "              accuracy_sum += batch_pixel_accuracy\n",
        "              \n",
        "              batch_mean_IOU = Metrics.mean_IOU(self.__get_predicted_labels_from_output(output), target)\n",
        "              mean_IOU_sum += batch_mean_IOU\n",
        "\n",
        "              if print_results:\n",
        "                  print('\\rTesting Batch {}/{}:\\tTotal Batch Loss Loss: {:.3f}\\tPixel Accuracy: {:.3f}\\tMean IOU: {:.3f}\\t\\tAverage IOU: {:.3f}'.format(n_batch+1, \n",
        "                                                                                                                                                        n_batches, \n",
        "                                                                                                                                                        average_batch_loss, \n",
        "                                                                                                                                                        batch_pixel_accuracy, \n",
        "                                                                                                                                                        batch_mean_IOU, \n",
        "                                                                                                                                                        mean_IOU_sum/(n_batch+1)), end='')\n",
        "                  if self.device.type=='cuda':\n",
        "                      print('\\tGPU Usage: {:.1f}%'.format(GPU.getGPUs()[0].memoryUtil*100), end='')\n",
        "                 \n",
        "        average_loss = loss_sum / n_batches \n",
        "        average_accuracy = accuracy_sum / n_batches\n",
        "        average_mean_IOU = mean_IOU_sum / n_batches\n",
        "\n",
        "        self.writer.add_scalar('Loss/test', average_loss, epoch_number)\n",
        "        self.writer.add_scalar('pixel_accuracy/test', average_accuracy, epoch_number)\n",
        "        self.writer.add_scalar('mean_IOU/test', average_mean_IOU, epoch_number)\n",
        "\n",
        "        if print_results:\n",
        "            print('\\r',end='')\n",
        "\n",
        "        return (average_loss, average_accuracy, average_mean_IOU)\n",
        "\n",
        "\n",
        "    def get_model_output(self, input):\n",
        "\n",
        "        return self.model(input.to(self.device))\n",
        "\n",
        "    \n",
        "    def __get_predicted_labels_from_output(self, output):\n",
        "\n",
        "        return torch.argmax(output, -3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHuWWf1oGVJN",
        "colab_type": "text"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x66NLg-tGXkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Visualization:\n",
        "\n",
        "    ID2COLOR = {label.id : np.array(label.color) for label in label2info.values()}\n",
        "\n",
        "    def get_color_array(network_output):\n",
        "\n",
        "        assert len(network_output.size())==3\n",
        "        ids = torch.argmax(network_output.to('cpu'),0)\n",
        "\n",
        "        channel1 = np.expand_dims(np.vectorize(lambda key:Visualization.ID2COLOR[key][0])(ids), -1)\n",
        "        channel2 = np.expand_dims(np.vectorize(lambda key:Visualization.ID2COLOR[key][1])(ids), -1)\n",
        "        channel3 = np.expand_dims(np.vectorize(lambda key:Visualization.ID2COLOR[key][2])(ids), -1)\n",
        "\n",
        "        return np.concatenate((channel1, channel2, channel3), -1).astype(np.uint8)\n",
        "\n",
        "\n",
        "    def visualize_label(label):\n",
        "\n",
        "        assert len(label.size())==2\n",
        "\n",
        "        channel1 = np.expand_dims(np.vectorize(lambda key:Visualization.ID2COLOR[key][0])(label), -1)\n",
        "        channel2 = np.expand_dims(np.vectorize(lambda key:Visualization.ID2COLOR[key][1])(label), -1)\n",
        "        channel3 = np.expand_dims(np.vectorize(lambda key:Visualization.ID2COLOR[key][2])(label), -1)\n",
        "\n",
        "        return Image.fromarray(np.concatenate((channel1, channel2, channel3), -1).astype(np.uint8))\n",
        "\n",
        "\n",
        "\n",
        "    def get_color_label(network_output, step=None):\n",
        "\n",
        "        return Image.fromarray(Visualization.get_color_array(network_output))\n",
        "\n",
        "\n",
        "    def visualize_in_tb(image_arr, log_dir, name=time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime())):\n",
        "\n",
        "        with SummaryWriter() as writer:\n",
        "            writer.add_image(name, image_arr, step)\n",
        "        return 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vf6YQLvQ_VW",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHFD79SIUJr6",
        "colab_type": "text"
      },
      "source": [
        "## Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFmPap70ZRtJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 5\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxMBkRm_-KQW",
        "colab_type": "text"
      },
      "source": [
        "## Loading Pre-Trained Parts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WT5h4ZRFKYOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_model(directory):\n",
        "        \n",
        "    saved_file = open(directory,\"rb\")\n",
        "    return pickle.load(saved_file)\n",
        "\n",
        "\n",
        "PATH = '/content/drive/My Drive/DL_Project/initial_2.pickle'\n",
        "\n",
        "model = load_model(scale_2_path) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mgKUFpa9mXG",
        "colab_type": "text"
      },
      "source": [
        "## Training the Initial Stages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ui_jjYfUsLVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=InitStage(scale=0.5, segmentation_name='deeplabv3+', backbone_name='mobilenetv2', num_classes=20, freeze_trunk=False, freeze_seg=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKipJCz5sTq1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.unfreeze_trunk()\n",
        "model.unfreeze_seg()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VujQklrUT3o8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LEARNING_RATE = 1e-4\n",
        "USE_GPU = True\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() and USE_GPU else \"cpu\")\n",
        "optimizer = optim.Adam(model.get_trainable_param(), lr=LEARNING_RATE)\n",
        "\n",
        "trainer = Trainer(model, optimizer, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pw7wQNjZU7lX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 20\n",
        "LOG_EVERY = 1\n",
        "\n",
        "train_results = None\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "\n",
        "    print_results=False\n",
        "    if not epoch%LOG_EVERY:\n",
        "        print_results=True\n",
        "        print(\"\\nEpoch {}:\".format(epoch))  \n",
        "\n",
        "    train_results = trainer.train_model(train_loader=train_loader, epoch_number=epoch)\n",
        "    test_results = trainer.test_model(test_loader=val_loader, epoch_number=epoch)\n",
        "\n",
        "    if USE_GPU:\n",
        "        torch.cuda.empty_cache()\n",
        "    \n",
        "    if print_results:\n",
        "        print('\\tAverage Loss: {:.3f}\\tPixel Accuracy: {:.3f}\\t Mean IOU: {:.3f}'.format(*train_results))\n",
        "        print('\\tAverage Loss: {:.3f}\\tPixel Accuracy: {:.3f}\\t Mean IOU: {:.3f}'.format(*test_results))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnMKePtL__Dx",
        "colab_type": "text"
      },
      "source": [
        "# Training the Whole Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk-uM4cEPkm1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 6\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpBNvypnDPdl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_model(directory):\n",
        "        \n",
        "    saved_file = open(directory,\"rb\")\n",
        "    return pickle.load(saved_file)\n",
        "\n",
        "\n",
        "PATH_SCALE_05 = '/content/drive/My Drive/DL_Project/best_model/model_scale_05.pickle'\n",
        "PATH_SCALE_1 = '/content/drive/My Drive/DL_Project/best_model/model_scale_1.pickle'\n",
        "PATH_SCALE_2 = '/content/drive/My Drive/DL_Project/best_model/model_scale_2.pickle'\n",
        "\n",
        "initial_stage_scale_05 = load_model(PATH_SCALE_05) \n",
        "initial_stage_scale_1 = load_model(PATH_SCALE_1) \n",
        "initial_stage_scale_2 = load_model(PATH_SCALE_2) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LZX-JAHJX3j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = HierachicalModel(n_stages=2, scales=(1, 0.5), segmentation='deeplabv3+', backbone='mobilenetv2')\n",
        "\n",
        "model.init_stage.trunk = initial_stage_scale_1.trunk\n",
        "model.init_stage.segmentation = initial_stage_scale_1.segmentation\n",
        "\n",
        "model.next_stages[0].trunk = initial_stage_scale_05.trunk\n",
        "model.next_stages[0].segmentation = initial_stage_scale_05.segmentation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oARMzl7rC4xF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.init_stage.freeze_trunk()\n",
        "model.init_stage.freeze_seg()\n",
        "\n",
        "model.next_stages[0].freeze_trunk()\n",
        "model.next_stages[0].freeze_seg()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jzZtjpvFCtdc",
        "colab": {}
      },
      "source": [
        "LEARNING_RATE = 1e-4\n",
        "USE_GPU = True\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() and USE_GPU else \"cpu\")\n",
        "optimizer = optim.Adam(model.get_trainable_param(), lr=LEARNING_RATE)\n",
        "\n",
        "trainer = Trainer(model, optimizer, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDMgcJoFQAg-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer.loss = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pEFpCo9UCtdg",
        "colab": {}
      },
      "source": [
        "EPOCHS = 20\n",
        "LOG_EVERY = 1\n",
        "\n",
        "train_results = None\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "\n",
        "    print_results=False\n",
        "    if not epoch%LOG_EVERY:\n",
        "        print_results=True\n",
        "        print(\"\\nEpoch {}:\".format(epoch))\n",
        "\n",
        "    if epoch==6:\n",
        "        model.init_stage.freeze_attention()\n",
        "        model.init_stage.unfreeze_trunk()\n",
        "        model.init_stage.unfreeze_seg()\n",
        "\n",
        "        model.next_stages[0].freeze_attention()\n",
        "        model.next_stages[0].freeze_trunk()\n",
        "        model.next_stages[0].freeze_seg()\n",
        "\n",
        "    \n",
        "    if epoch==8:\n",
        "        model.init_stage.freeze_attention()\n",
        "        model.init_stage.unfreeze_trunk()\n",
        "        model.init_stage.unfreeze_seg()\n",
        "\n",
        "        model.next_stages[0].freeze_attention()\n",
        "        model.next_stages[0].freeze_trunk()\n",
        "        model.next_stages[0].freeze_seg()\n",
        "\n",
        "    if epoch==10:\n",
        "        model.init_stage.unfreeze_attention()\n",
        "        model.init_stage.freeze_trunk()\n",
        "        model.init_stage.freeze_seg()\n",
        "\n",
        "        model.next_stages[0].unfreeze_attention()\n",
        "        model.next_stages[0].freeze_trunk()\n",
        "        model.next_stages[0].freeze_seg()\n",
        "\n",
        "\n",
        "    train_results = trainer.train_model(train_loader=train_loader, epoch_number=epoch)\n",
        "    test_results = trainer.test_model(test_loader=val_loader, epoch_number=epoch)\n",
        "\n",
        "    if USE_GPU:\n",
        "        torch.cuda.empty_cache()\n",
        "    \n",
        "    if print_results:\n",
        "        print('\\tAverage Loss: {:.3f}\\tPixel Accuracy: {:.3f}\\t Mean IOU: {:.3f}'.format(*train_results))\n",
        "        print('\\tAverage Loss: {:.3f}\\tPixel Accuracy: {:.3f}\\t Mean IOU: {:.3f}'.format(*test_results))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMgI-u3w-R4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuY9PHRw-R1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1or4lE5yJ244",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RvzBhljR9pB",
        "colab_type": "text"
      },
      "source": [
        "# Visualizing the Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rj8xSuqfEqOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}